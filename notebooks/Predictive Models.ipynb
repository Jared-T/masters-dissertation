{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import openpyxl\n",
    "import os\n",
    "import tslearn\n",
    "\n",
    "file_path = os.path.join(\"..\", \"data\", \"Final Transactions With Flags.csv\")\n",
    "data_in = pd.read_csv(file_path, low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f16dcf32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Transaction Date', 'REG_NUM', 'Merchant Name', 'No. of Litres',\n",
       "       'Transaction Amount', 'VEHICLE MAKE', 'MODEL DERIVATIVE', 'DEPARTMENT',\n",
       "       'RATE CARD CATEGORY', 'Site', 'District', 'Site Lat', 'Site Long',\n",
       "       'Merchant Lat', 'Merchant Long', 'Fuel Type',\n",
       "       'Estimated Price Per Litre', 'Coastal Petrol', 'Inland Petrol',\n",
       "       'Coastal Diesel', 'Inland Diesel', 'Month Name', 'Weekday Name',\n",
       "       'Average_Category_Amount', 'Transaction_Amount_Flag',\n",
       "       'Days_Between_Transactions', 'Transaction_Frequency_Flag',\n",
       "       'Coastal Diesel Adjusted', 'Price Difference', 'Fuel_Price_Flag',\n",
       "       'Number_of_Flags'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_in.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a864fa27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Number_of_Flags\n",
       "0    140110\n",
       "1     33707\n",
       "2      2103\n",
       "3        13\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_in['Number_of_Flags'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f83c66",
   "metadata": {},
   "source": [
    "# Create the train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e247f397",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the columns from the data that we want to use\n",
    "data = data_in[['Transaction Amount', 'No. of Litres', 'District', 'VEHICLE MAKE', 'Fuel Type', 'Number_of_Flags', 'RATE CARD CATEGORY']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17505209",
   "metadata": {},
   "source": [
    "# Linear Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "acea28f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Import Libraries\n",
    "import pandas as pd\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "# 2. Data Preprocessing\n",
    "# Define categorical and numerical features\n",
    "categorical_features = ['District', 'VEHICLE MAKE', 'Fuel Type', 'RATE CARD CATEGORY']\n",
    "numerical_features = ['Transaction Amount', 'No. of Litres']\n",
    "\n",
    "# Define transformations for categorical and numerical features\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_features),\n",
    "        ('cat', OneHotEncoder(), categorical_features)\n",
    "    ])\n",
    "\n",
    "# Split data into features and target variable\n",
    "X = data.drop(['Number_of_Flags'], axis=1)\n",
    "y = data['Number_of_Flags']\n",
    "\n",
    "# Split data into training and testing sets using stratified sampling\n",
    "splitter = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=1)\n",
    "train_index, test_index = next(splitter.split(X, y))\n",
    "X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "# Define LinearSVC with specific parameters\n",
    "linear_svc = LinearSVC(max_iter=10000, dual=\"auto\", class_weight='balanced', random_state=1)\n",
    "\n",
    "# Create a calibrated classifier with LinearSVC\n",
    "calibrated_svc = CalibratedClassifierCV(estimator=linear_svc, method='sigmoid', cv=5)\n",
    "\n",
    "# Create a pipeline with the calibrated classifier\n",
    "pipeline_svm = Pipeline([\n",
    "    ('preprocessor', preprocessor), \n",
    "    ('classifier', calibrated_svc)\n",
    "])\n",
    "\n",
    "# Fit the model\n",
    "pipeline_svm.fit(X_train, y_train)\n",
    "\n",
    "# 4. Model Evaluation\n",
    "# Predictions\n",
    "y_pred = pipeline_svm.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f7ea9f50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for Linear SVM:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.96      0.90     28022\n",
      "           1       0.56      0.25      0.34      6741\n",
      "           2       0.00      0.00      0.00       421\n",
      "           3       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.81     35187\n",
      "   macro avg       0.35      0.30      0.31     35187\n",
      "weighted avg       0.77      0.81      0.78     35187\n",
      "\n",
      "Confusion Matrix:\n",
      " [[26961  1061     0     0]\n",
      " [ 5071  1670     0     0]\n",
      " [  177   244     0     0]\n",
      " [    1     2     0     0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jared/opt/anaconda3/envs/scientificProject/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jared/opt/anaconda3/envs/scientificProject/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jared/opt/anaconda3/envs/scientificProject/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Evaluation\n",
    "print(\"Classification Report for Linear SVM:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23212a5",
   "metadata": {},
   "source": [
    "# Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9440a5fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for Naive Bayes:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.14      0.24     28022\n",
      "           1       0.26      0.02      0.03      6741\n",
      "           2       0.01      0.56      0.02       421\n",
      "           3       0.00      1.00      0.00         3\n",
      "\n",
      "    accuracy                           0.12     35187\n",
      "   macro avg       0.30      0.43      0.07     35187\n",
      "weighted avg       0.80      0.12      0.20     35187\n",
      "\n",
      "Confusion Matrix for Naive Bayes:\n",
      " [[ 3893   345 19376  4408]\n",
      " [  252   120  4616  1753]\n",
      " [    4     3   236   178]\n",
      " [    0     0     0     3]]\n"
     ]
    }
   ],
   "source": [
    "# 1. Import Libraries for Naive Bayes\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.base import TransformerMixin\n",
    "\n",
    "# Define a custom transformer to convert sparse matrix to dense\n",
    "class DenseTransformer(TransformerMixin):\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None, **fit_params):\n",
    "        return X.toarray()\n",
    "\n",
    "\n",
    "# Preprocessors for numerical and categorical features for Naive Bayes\n",
    "numeric_transformer_nb = Pipeline(steps=[\n",
    "    ('scaler_nb', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer_nb = Pipeline(steps=[\n",
    "    ('onehot_nb', OneHotEncoder(handle_unknown='ignore')),\n",
    "    ('to_dense_nb', DenseTransformer())  # Convert to dense\n",
    "])\n",
    "\n",
    "# Combine preprocessors for Naive Bayes\n",
    "preprocessor_nb = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num_nb', numeric_transformer_nb, numerical_features),\n",
    "        ('cat_nb', categorical_transformer_nb, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Split data into training and testing sets using stratified sampling\n",
    "splitter = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=1)\n",
    "train_index, test_index = next(splitter.split(X, y))\n",
    "X_train_nb, X_test_nb = X.iloc[train_index], X.iloc[test_index]\n",
    "y_train_nb, y_test_nb = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "# 3. Model Training for Naive Bayes\n",
    "# Create a pipeline for Naive Bayes - switch out to use CategoricalNB for categorical features (more efficient)\n",
    "pipeline_nb = make_pipeline(\n",
    "    preprocessor_nb,\n",
    "    GaussianNB()  \n",
    ")\n",
    "\n",
    "# Fit the model for Naive Bayes\n",
    "pipeline_nb.fit(X_train_nb, y_train_nb)\n",
    "\n",
    "# 4. Model Evaluation for Naive Bayes\n",
    "# Predictions for Naive Bayes\n",
    "y_pred_nb = pipeline_nb.predict(X_test_nb)\n",
    "\n",
    "# Evaluation metrics for Naive Bayes\n",
    "print(\"Classification Report for Naive Bayes:\\n\", classification_report(y_test_nb, y_pred_nb))\n",
    "print(\"Confusion Matrix for Naive Bayes:\\n\", confusion_matrix(y_test_nb, y_pred_nb))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da064a1",
   "metadata": {},
   "source": [
    "# XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "21f9d379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for XGBoost:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.95      0.91     28022\n",
      "           1       0.62      0.43      0.51      6741\n",
      "           2       0.58      0.15      0.24       421\n",
      "           3       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.84     35187\n",
      "   macro avg       0.52      0.38      0.41     35187\n",
      "weighted avg       0.82      0.84      0.82     35187\n",
      "\n",
      "Confusion Matrix for XGBoost:\n",
      " [[26533  1477    12     0]\n",
      " [ 3819  2891    31     0]\n",
      " [   98   261    62     0]\n",
      " [    0     2     1     0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jared/opt/anaconda3/envs/scientificProject/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jared/opt/anaconda3/envs/scientificProject/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jared/opt/anaconda3/envs/scientificProject/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# 1. Import Libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Define transformations for categorical and numerical features\n",
    "preprocessor_xgb = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num_xgb', StandardScaler(), numerical_features),\n",
    "        ('cat_xgb', OneHotEncoder(), categorical_features)\n",
    "    ])\n",
    "\n",
    "# Split data into training and testing sets using stratified sampling\n",
    "splitter = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=1)\n",
    "train_index, test_index = next(splitter.split(X, y))\n",
    "X_train_xgb, X_test_xgb = X.iloc[train_index], X.iloc[test_index]\n",
    "y_train_xgb, y_test_xgb = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "# 3. Model Training and Hyperparameter Tuning\n",
    "# Create a pipeline\n",
    "pipeline_xgb = Pipeline([\n",
    "    ('preprocessor_xgb', preprocessor_xgb),\n",
    "    ('classifier_xgb', XGBClassifier(use_label_encoder=False, eval_metric='logloss'))\n",
    "])\n",
    "\n",
    "# Optional: Define parameters for GridSearchCV\n",
    "param_grid_xgb = {\n",
    "    'classifier_xgb__n_estimators': [50, 100, 150, 200, 300],  # Number of trees\n",
    "    'classifier_xgb__learning_rate': [0.001, 0.01, 0.1, 0.5],  # Learning rate\n",
    "}\n",
    "\n",
    "# Optional: Create GridSearchCV object\n",
    "grid_search_xgb = GridSearchCV(pipeline_xgb, param_grid_xgb, cv=5, verbose=1, n_jobs=-1)\n",
    "\n",
    "# Fit the model (use grid_search_xgb.fit(X_train_xgb, y_train_xgb) if using GridSearchCV)\n",
    "pipeline_xgb.fit(X_train_xgb, y_train_xgb)\n",
    "\n",
    "# 4. Model Evaluation\n",
    "# Predictions (use grid_search_xgb.predict(X_test_xgb) if using GridSearchCV)\n",
    "y_pred_xgb = pipeline_xgb.predict(X_test_xgb)\n",
    "\n",
    "# Evaluation metrics\n",
    "print(\"Classification Report for XGBoost:\\n\", classification_report(y_test_xgb, y_pred_xgb))\n",
    "print(\"Confusion Matrix for XGBoost:\\n\", confusion_matrix(y_test_xgb, y_pred_xgb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594bfb3c",
   "metadata": {},
   "source": [
    "# Generating figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "873a58a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "af36b4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, model_name, dpi=300):\n",
    "    matrix = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    # Calculate the total number of samples\n",
    "    total = matrix.sum()\n",
    "    \n",
    "    # Calculate the percentage for each cell in the confusion matrix\n",
    "    matrix_percent = matrix / total * 100\n",
    "    \n",
    "    # Create a text annotation matrix for displaying both values and percentages\n",
    "    annot_matrix = [[f\"{value}\\n({percent:.2f}%)\" for value, percent in zip(row, row_percent)]\n",
    "                    for row, row_percent in zip(matrix, matrix_percent)]\n",
    "    \n",
    "    plt.figure(figsize=(8, 8))\n",
    "    sns.heatmap(matrix, annot=annot_matrix, fmt='', cmap='cividis', square=True, cbar=False)\n",
    "    \n",
    "    plt.xlabel('Predicted Label', size=13)\n",
    "    plt.ylabel('True Label', size=13)\n",
    "    \n",
    "    # Add a title with the model name\n",
    "    #plt.title(f'Confusion Matrix for {model_name}', size=16)\n",
    "    \n",
    "    # Save the plot as a PDF file\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'../plots/modelling/{model_name}_confusion_matrix.pdf', format='pdf', dpi=dpi)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "853f58db",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(y_test, y_pred_nb, \"Naive Bayes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a0392976",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(y_test, y_pred, \"Linear_SVM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "36028968",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(y_test, y_pred_xgb, \"XGBoost\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scientificProject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
